{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get started with testing in Python\n",
    "https://learn.microsoft.com/en-us/training/modules/python-get-started-testing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "https://learn.microsoft.com/en-us/training/modules/python-get-started-testing/1-introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand Python testing with the unittest module\n",
    "https://learn.microsoft.com/en-us/training/modules/python-get-started-testing/2-python-unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import unittest\n",
    "\n",
    "# class TestAssertions(unittest.TestCase):\n",
    "\n",
    "#     def test_equals(self):\n",
    "#         self.assertEqual('one string', 'one string')\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     unittest.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to run a test file. Let's look again at the end of the test_assertions.py file, where the unittest.main() call allows running the tests by executing the file with Python: <br>\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n",
    "<br>\n",
    "The test run is possible because of the if block at the end, where the condition is only met when running the script directly with Python. Let's check the output when running it in that way:<br>\n",
    "$ python test_assertions.py <br>\n",
    "\n",
    "Another way to run tests with the unittest module is by using it with the Python executable. This time, it isn't necessary to specify the filename because tests can be discovered automatically:<br>\n",
    "\n",
    "$ python -m unittest\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naming Convention\n",
    "The class and method names follow a test convention. The convention is that they need to be prefixed with test. Although it isn't required, test classes use camel-casing, and test methods are lower-case, and words are separated with an underscore. For example, here's how a test for customer accounts that verify creation and deletion could look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TestAccounts(unittest.TestCase):\n",
    "\n",
    "#     def test_creation(self):\n",
    "#         self.assertTrue(account.create())\n",
    "\n",
    "#     def test_deletion(self):\n",
    "#         self.assertTrue(account.delete())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test classes or methods that don't follow these conventions won't get run. Although it might seem like a problem not to run every single method in a class, it can be helpful when creating non-test code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assertions and assert methods\n",
    "It's essential to use assert methods instead of Python's built-in assert() function to have rich reporting when failures happen. The test_assertion.py example uses self.assertEqual(), one of the many special methods from the unittest.TestCase class to ensure that two values are equal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.assertEqual(\"one string\", \"one string\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, both strings are equal, so the test passes. Testing for equality is one of the many different assertions that the unittest.TestCase class offers. Although there are more than 30 assert methods, the following are most commonly used aside from self.assertEqual():\n",
    "\n",
    "self.assertTrue(value): Ensure that value is true. <br>\n",
    "self.assertFalse(value): Ensure that value is false.<br>\n",
    "self.assertNotEqual(a, b): Check that a and b aren't equal.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Failures and reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Write a unit test with the unittest module\n",
    "https://learn.microsoft.com/en-us/training/modules/python-get-started-testing/3-exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - Add a file for this exercise\n",
    "added test_exercise.py in the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Run the tests and identify the failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Fix the bug and make the tests pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 - Add new code with tests\n",
    "1. Update the function so that it raises an AttributeError if a non-string value is used. This case can be detected by catching an AttributeError when calling value.lower() because only strings have a lower() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges with testing\n",
    "https://learn.microsoft.com/en-us/training/modules/python-get-started-testing/5-challenges-with-testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lack of testing\n",
    "When software projects are built with no tests (or an inadequate number of tests), code can deteriorate, become brittle, and harder to understand. Tests make code accountable for its behavior, and when tests are introduced, it forces an engineer to make code easier to test.\n",
    "\n",
    "There are a few positive side-effects of testing that you can recognize in your code. Functions and methods written with testing in mind, tend to:\n",
    "\n",
    "Be no longer than about a dozen lines long.\n",
    "\n",
    "Have a single responsibility instead of doing many different things.\n",
    "\n",
    "Have a single or minimal amount of input instead of many arguments and values.\n",
    "\n",
    "Short, single-responsibility, and minimal input makes code easier to understand, maintain, and test. When testing isn't involved, it's common to see smaller functions grow into several hundred lines, doing many things. The code evolves this way because there's no accountability preventing the unnecessary complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Legacy code\n",
    "One way to think about untested code is to label it as legacy code. It's common to find untested code in software projects. Code can go untested for several reasons, including A lack of experience with testing, or development practices that don't allow sufficient time to consider testing as part of producing software.\n",
    "\n",
    "As already mentioned, one characteristic of untested code is that it's hard to grasp, and can often become complex for the same reason. A side-effect of all these problems is that it makes code even more difficult to deal with, causing functions (or methods) to keep growing with more logic and more intertwined code paths.\n",
    "\n",
    "The smaller the function, the easier it will be to test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slow and unreliable tests\n",
    "Although an existing test suite is great to start with, it might be problematic when it contains slow or unreliable tests. A developer will be more inclined to run tests often if they provide fast feedback. If a test suite takes hours to run instead of minutes (or seconds), a developer can't afford to run it as often. When the feedback loop is slow, the development process gets compromised.\n",
    "\n",
    "Similarly, you may find situations where a test can fail without an apparent reason. Unreliable tests are sometimes called flaky. The main responsibility of a test suite is to demonstrate that the code under test is meeting expectations set by the tests themselves. If tests are unreliable, you can't really tell if the code needs to be changed, or if a patch has introduced a regression.\n",
    "\n",
    "Unreliable (or flaky) tests should be fixed or otherwise removed from the suite. Not every test can be fast, and some types of testing like integration tests can be slow. But having a solid test suite that provides fast feedback is essential.\n",
    "\n",
    "#### Lack of automation\n",
    "When testing doesn't happen in an automated way, it's easy to forget what to test and testing can become error prone. Even on small software projects it's easy to forget if changing a condition in a function can have a (negative) side-effect somewhere else in the code base. When a software developer isn't tasked with remembering what and when to test because it all happens automatically, then confidence in the software, the tests, and the overall system increases.\n",
    "\n",
    "Automation is all about removing repetitive tasks and reducing the steps necessary for an action to happen. Automated Testing can happen when code is pushed to a remote repository, or even before it gets merged. Preventing defective code from getting into production code without manual checks is critical for a robust application.\n",
    "\n",
    "#### Test tooling\n",
    "Some of the challenges come from a lack of testing, while others are related to poor testing experiences and not knowing what techniques to apply. We've already mentioned legacy code in this module, and how untested code can keep growing in size and complexity. Test coverage tools can accurately tell you which code paths are tested, and which aren't being covered by existing tests.\n",
    "\n",
    "Relying on tooling and testing libraries is a great way to reduce the amount of effort it takes to produce good tests. Depending on the language and application being tested, you must find solutions that can make testing easier and more robust.\n",
    "\n",
    "Here are some examples of what those tools should be:\n",
    "\n",
    "A test coverage tool for reporting on tested and untested code paths.\n",
    "\n",
    "A test runner that can collect, execute, and rerun specific tests.\n",
    "\n",
    "A CI/CD environment that can automatically run tests and prevent defective code from getting merged or deployed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of testing and how to use them\n",
    "https://learn.microsoft.com/en-us/training/modules/python-get-started-testing/6-testing-types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit testing\n",
    "The primary focus of unit testing is testing the smallest piece of code logic possible. The side-effect of this type of testing is speed. Unit tests will usually run quickly since (ideally) no external resources like databases, websites, or network calls are needed.\n",
    "\n",
    "Functions and methods that are long and complex, with multiple logical conditions will be difficult to unit test. Unit testing forces developers to think about complexity in code and keeping it to a minimum. In general, the shorter the function or method is, the easier it will be to test it.\n",
    "\n",
    "There aren't any hard rules about unit testing, but in general the following are commonly accepted norms about unit tests:\n",
    "\n",
    "They test the smallest piece of logic possible.<br>\n",
    "Functions, methods, or classes are tested as isolated as possible, avoiding the need to set up other functions, methods, or classes as a requirement.<br>\n",
    "No external services like databases or network services are needed for them to run.<br>\n",
    "\n",
    "#### Integration testing\n",
    "Integration testing usually focuses on testing logic that will interact with other pieces of logic in a code project. Sometimes, these tests will require connecting to a database or other external service.\n",
    "\n",
    "For example, a function that checks a username and password will probably need to connect to a database to verify existing data. A test for that function could require a database with existing information. These types of tests will require slightly more complex setups than unit tests and may take longer to execute.\n",
    "\n",
    "Here are some accepted norms about integration testing:\n",
    "\n",
    "Not as fast as unit tests, and they tend to require more setup upfront before running.<br>\n",
    "Functions, methods, or classes are tested with functionality in other functions, methods, or classes.<br>\n",
    "An external service might be used, but not all the services for the application.<br>\n",
    "\n",
    "#### Functional testing\n",
    "Functional testing usually requires running an application as a whole. For a website, a functional test might need a web server, a database, and any other required service for the application to run. The idea is to replicate the application running in the production environment as closely as possible.\n",
    "\n",
    "Since it's not always possible to accurately replicate a production environment, special care needs to be put into the drawbacks of the setup. For example, if a website has 1 terabyte of data in production, it's probably fine to test with a subset of the production data. However, it wouldn't be advisable to use an embedded database like SQLite instead of the same PostgreSQL database used in production. Version differences of external services like databases can cause a test to pass but fail in production.\n",
    "\n",
    "Functional testing has some of the following aspects:\n",
    "\n",
    "Not as fast as unit tests, and they tend to require more setup upfront before running.<br>\n",
    "Functions, methods, or classes are tested with functionality in other functions, methods, or classes.<br>\n",
    "An external service might be used, but not all the services for the application.<br>\n",
    "Since functional tests require more services, a reproduction of the production environment, and the most complex setup of the test types, it will usually be time consuming and resource intensive.<br>\n",
    "\n",
    "A single functional test for an online retail store could involve the following steps to complete:\n",
    "\n",
    "Sign up for a new user.<br>\n",
    "Select a given product and add it to the virtual shopping cart.<br>\n",
    "Complete the shipping and billing information.<br>\n",
    "Select the \"buy\" button to complete the purchase.<br>\n",
    "Verify that the new account exists, billing and shipping information is correct, and inventory was updated.<br>\n",
    "\n",
    "#### Continuous Integration\n",
    "Although CI (Continuous Integration) isn't a type of testing, it's an important piece that has to do with every type of testing. When a testing plan is put into place, it's essential to have something that will run the tests in an automated way. A CI environment is the right place to automatically run tests. These tests can run on a schedule, be triggered by an event, or be manually executed. This environment will usually be consistent with where the code or project needs to run.\n",
    "\n",
    "The foundation for a good CI process is automation. Automation is what will set a consistent (and well known) environment. Without a repetitive and known testing environment, debugging problems and failed tests would be time consuming or even impossible.\n",
    "\n",
    "Triggered by an event<br>\n",
    "For example, if a developer wants to merge changes to the main branch, it's ideal to ensure that the changes won't cause breakage. A CI system can automatically run tests from a developer's branch and alert them when there's a failure. Preventing code that has failed CI from being merged, is a good way to increase confidence and robustness in a project.\n",
    "\n",
    "Running on a schedule<br>\n",
    "As already mentioned, automation is a crucial part of a CI process. Usually, with the setup of any test type, dependencies must be installed in order for tests to work. Using a schedule for a test run (for example a nightly run) ensures that a project builds correctly even when dependencies change.\n",
    "\n",
    "A recurrent scheduled test run can also be helpful when running tests that take a long time to complete. If a software project has functional tests that take a few hours to complete, it would be more efficient to run those tests at night. so the team can work on failures first thing in the morning.\n",
    "\n",
    "Manual triggering<br>\n",
    "Finally, even though scheduled and event-driven test runs are useful, it's good to be able to run a test suite manually. For example, when a test suite is known to have a problem, a developer can try a fix by rerunning a previously failed run. This feedback loop allows fixes to be tested without the need for a specific event or schedule. Further, a CI run might allow configuration changes for a test to run which can be altered ad-hoc to ensure certain conditions are met."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mslearn_py31106",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
