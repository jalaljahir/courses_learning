{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "705d67cb",
   "metadata": {},
   "source": [
    "#### Exponential Smoothing with Statesmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21888d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "387124d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dates = pd.date_range(start='2012-01-01', end='2016-12-01', freq='MS')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00e4ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sales data (as above)\n",
    "sales_data = []\n",
    "for pid in range(1, 2851):\n",
    "    num_obs = np.random.randint(10, 60)\n",
    "    idx = np.random.choice(len(dates), num_obs, replace=False)\n",
    "    sel_dates = dates[idx]\n",
    "    base = np.random.uniform(50, 200)\n",
    "    months = np.array([d.month - 1 for d in sel_dates])\n",
    "    month_sin = np.sin(2 * np.pi * months / 12)\n",
    "    month_cos = np.cos(2 * np.pi * months / 12)\n",
    "    time = np.array([(d - dates[0]).days / 30.0 for d in sel_dates])\n",
    "    sales = base + 0.5 * time + 15 * month_sin + 5 * month_cos + np.random.normal(0, 10, num_obs)\n",
    "    sales = np.maximum(sales, 0)\n",
    "    temp_df = pd.DataFrame({'product_id': pid, 'date': sel_dates, 'sales': sales})\n",
    "    sales_data.append(temp_df)\n",
    "df_sales = pd.concat(sales_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b7e2167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate costs\n",
    "df_costs = pd.DataFrame({\n",
    "    'product_id': range(1, 2851),\n",
    "    'unit_opportunity_loss': np.random.uniform(0.5, 5.0, 2850),\n",
    "    'unit_inventory_cost': np.random.uniform(0.1, 2.0, 2850)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "396c7b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        product_id  forecast_dec2016\n",
      "count  2850.000000       2850.000000\n",
      "mean   1425.500000        140.183708\n",
      "std     822.868459         43.236829\n",
      "min       1.000000         60.654784\n",
      "25%     713.250000        103.207737\n",
      "50%    1425.500000        140.979247\n",
      "75%    2137.750000        177.139646\n",
      "max    2850.000000        222.318032\n"
     ]
    }
   ],
   "source": [
    "# Forecast\n",
    "forecasts = {}\n",
    "for pid in range(1, 2851):\n",
    "    ts_df = df_sales[df_sales.product_id == pid].set_index('date').sort_index()['sales']\n",
    "    if len(ts_df) < 12:\n",
    "        forecasts[pid] = ts_df.mean() if len(ts_df) > 0 else 0\n",
    "    else:\n",
    "        try:\n",
    "            model = ExponentialSmoothing(ts_df, trend='add', seasonal='add', seasonal_periods=12, damped_trend=True).fit(disp=False)\n",
    "            pred = model.forecast(1)[0]\n",
    "            forecasts[pid] = max(pred, 0)\n",
    "        except:\n",
    "            forecasts[pid] = ts_df.mean()\n",
    "df_forecast = pd.DataFrame(list(forecasts.items()), columns=['product_id', 'forecast_dec2016'])\n",
    "\n",
    "# Save/export as needed (e.g., df_forecast.to_csv('forecasts.csv'))\n",
    "print(df_forecast.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defe08df",
   "metadata": {},
   "source": [
    "#### Linear and Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cfa4454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b5d0aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dates = pd.date_range(start='2012-01-01', end='2016-12-01', freq='MS')[:-1]\n",
    "n_months = len(dates)\n",
    "n_products = 2850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45246fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sales data\n",
    "sales_data = []\n",
    "for pid in range(1, n_products + 1):\n",
    "    num_obs = np.random.randint(10, 60)\n",
    "    idx = np.random.choice(n_months, num_obs, replace=False)\n",
    "    sel_dates = dates[idx]\n",
    "    base = np.random.uniform(50, 200)\n",
    "    months = np.array([d.month - 1 for d in sel_dates])\n",
    "    month_sin = np.sin(2 * np.pi * months / 12)\n",
    "    month_cos = np.cos(2 * np.pi * months / 12)\n",
    "    time = np.array([(d - dates[0]).days / 30.0 for d in sel_dates])\n",
    "    sales = base + 0.5 * time + 15 * month_sin + 5 * month_cos + np.random.normal(0, 10, num_obs)\n",
    "    sales = np.maximum(sales, 0)\n",
    "    temp_df = pd.DataFrame({'product_id': pid, 'date': sel_dates, 'sales': sales})\n",
    "    sales_data.append(temp_df)\n",
    "df_sales = pd.concat(sales_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa814456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate costs\n",
    "df_costs = pd.DataFrame({\n",
    "    'product_id': range(1, n_products + 1),\n",
    "    'unit_opportunity_loss': np.random.uniform(0.5, 5.0, n_products),\n",
    "    'unit_inventory_cost': np.random.uniform(0.1, 2.0, n_products)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec0d097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full TS\n",
    "full_ts = []\n",
    "for pid in range(1, n_products + 1):\n",
    "    ts_df = df_sales[df_sales.product_id == pid].set_index('date').sort_index()\n",
    "    full_series = pd.Series(index=dates, dtype=float)\n",
    "    full_series.update(ts_df['sales'])\n",
    "    full_ts.append(full_series)\n",
    "ts_df_full = pd.DataFrame(full_ts).T\n",
    "ts_df_full.index = dates\n",
    "ts_df_full.columns = range(1, n_products + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "170a7230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(ts):\n",
    "    trend = np.arange(len(ts))\n",
    "    month = ts.index.month\n",
    "    month_sin = np.sin(2 * np.pi * (month - 1) / 12)\n",
    "    month_cos = np.cos(2 * np.pi * (month - 1) / 12)\n",
    "    lag1 = ts.shift(1)\n",
    "    lag12 = ts.shift(12)\n",
    "    return pd.DataFrame({'trend': trend, 'month_sin': month_sin, 'month_cos': month_cos, 'lag1': lag1, 'lag12': lag12}, index=ts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1884b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actuals\n",
    "actuals = {}\n",
    "np.random.seed(42)\n",
    "for pid in range(1, n_products + 1):\n",
    "    last_sales = ts_df_full[pid].dropna().iloc[-1] if len(ts_df_full[pid].dropna()) > 0 else 0\n",
    "    actual = max(last_sales + np.random.normal(0, 15), 0)\n",
    "    actuals[pid] = actual\n",
    "df_actual = pd.DataFrame(list(actuals.items()), columns=['product_id', 'actual_dec2016'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90da8052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW\n",
    "forecasts_hw = {}\n",
    "for pid in range(1, n_products + 1):\n",
    "    ts_sparse = df_sales[df_sales.product_id == pid].set_index('date').sort_index()['sales']\n",
    "    if len(ts_sparse) < 12:\n",
    "        forecasts_hw[pid] = ts_sparse.mean() if len(ts_sparse) > 0 else 0\n",
    "        continue\n",
    "    try:\n",
    "        ts_interp = ts_sparse.asfreq('MS').interpolate('linear')\n",
    "        model = ExponentialSmoothing(ts_interp, trend='add', seasonal='add', seasonal_periods=12, damped_trend=True).fit(disp=False)\n",
    "        pred = model.forecast(1)[0]\n",
    "        forecasts_hw[pid] = max(pred, 0)\n",
    "    except:\n",
    "        forecasts_hw[pid] = ts_sparse.mean()\n",
    "df_forecast_hw = pd.DataFrame(list(forecasts_hw.items()), columns=['product_id', 'forecast_dec2016'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62945850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR\n",
    "forecasts_lr = {}\n",
    "for pid in range(1, n_products + 1):\n",
    "    ts = ts_df_full[pid]\n",
    "    feat = create_features(ts)\n",
    "    y = ts\n",
    "    mask = ~(y.isna() | feat['lag1'].isna() | feat['lag12'].isna())\n",
    "    if mask.sum() < 3:\n",
    "        forecasts_lr[pid] = y.dropna().mean() if len(y.dropna()) > 0 else 0\n",
    "        continue\n",
    "    X = feat.loc[mask, ['trend', 'month_sin', 'month_cos', 'lag1', 'lag12']].values\n",
    "    y_train = y.loc[mask].values\n",
    "    model = LinearRegression().fit(X, y_train)\n",
    "    last_lag1 = ts.dropna().iloc[-1] if len(ts.dropna()) > 0 else 0\n",
    "    lag12_val = ts['2015-12-01'] if not pd.isna(ts['2015-12-01']) else y.dropna().mean() if len(y.dropna()) > 0 else 0\n",
    "    dec_X = np.array([[58, np.sin(2 * np.pi * 11 / 12), np.cos(2 * np.pi * 11 / 12), last_lag1, lag12_val]])\n",
    "    pred = model.predict(dec_X)[0]\n",
    "    forecasts_lr[pid] = max(pred, 0)\n",
    "df_forecast_lr = pd.DataFrame(list(forecasts_lr.items()), columns=['product_id', 'forecast_dec2016'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56a1864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "forecasts_rf = {}\n",
    "for pid in range(1, n_products + 1):\n",
    "    ts = ts_df_full[pid]\n",
    "    feat = create_features(ts)\n",
    "    y = ts\n",
    "    mask = ~(y.isna() | feat['lag1'].isna() | feat['lag12'].isna())\n",
    "    if mask.sum() < 5:\n",
    "        forecasts_rf[pid] = y.dropna().mean() if len(y.dropna()) > 0 else 0\n",
    "        continue\n",
    "    X = feat.loc[mask, ['trend', 'month_sin', 'month_cos', 'lag1', 'lag12']].values\n",
    "    y_train = y.loc[mask].values\n",
    "    model = RandomForestRegressor(n_estimators=50, random_state=42).fit(X, y_train)\n",
    "    last_lag1 = ts.dropna().iloc[-1] if len(ts.dropna()) > 0 else 0\n",
    "    lag12_val = ts['2015-12-01'] if not pd.isna(ts['2015-12-01']) else y.dropna().mean() if len(y.dropna()) > 0 else 0\n",
    "    dec_X = np.array([[58, np.sin(2 * np.pi * 11 / 12), np.cos(2 * np.pi * 11 / 12), last_lag1, lag12_val]])\n",
    "    pred = model.predict(dec_X)[0]\n",
    "    forecasts_rf[pid] = max(pred, 0)\n",
    "df_forecast_rf = pd.DataFrame(list(forecasts_rf.items()), columns=['product_id', 'forecast_dec2016'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44d9eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Inside product loop\n",
    "forecasts_xgb = {}\n",
    "for pid in range(1, n_products + 1):\n",
    "    model = XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)\n",
    "    model.fit(X, y_train)\n",
    "    pred = model.predict(dec_X)[0]\n",
    "    forecasts_xgb[pid] = max(pred, 0)\n",
    "df_forecast_xgb = pd.DataFrame(list(forecasts_xgb.items()), columns=['product_id', 'forecast_dec2016'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86a6df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "df_eval = df_actual.merge(df_forecast_hw.rename(columns={'forecast_dec2016': 'forecast_hw'}), on='product_id') \\\n",
    "                  .merge(df_forecast_lr.rename(columns={'forecast_dec2016': 'forecast_lr'}), on='product_id') \\\n",
    "                  .merge(df_forecast_rf.rename(columns={'forecast_dec2016': 'forecast_rf'}), on='product_id') \\\n",
    "                  .merge(df_forecast_xgb.rename(columns={'forecast_dec2016': 'forecast_xgb'}), on='product_id') \\\n",
    "                  .merge(df_costs, on='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26665078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        product_id  forecast_dec2016\n",
      "count  2850.000000       2850.000000\n",
      "mean   1425.500000        140.183708\n",
      "std     822.868459         43.236829\n",
      "min       1.000000         60.654784\n",
      "25%     713.250000        103.207737\n",
      "50%    1425.500000        140.979247\n",
      "75%    2137.750000        177.139646\n",
      "max    2850.000000        222.318032\n",
      "        product_id  forecast_dec2016\n",
      "count  2850.000000       2850.000000\n",
      "mean   1425.500000        149.071744\n",
      "std     822.868459         53.555884\n",
      "min       1.000000          0.000000\n",
      "25%     713.250000        109.603625\n",
      "50%    1425.500000        149.270540\n",
      "75%    2137.750000        186.456757\n",
      "max    2850.000000        791.061975\n",
      "        product_id  forecast_dec2016\n",
      "count  2850.000000       2850.000000\n",
      "mean   1425.500000        143.780526\n",
      "std     822.868459         43.754925\n",
      "min       1.000000         50.851755\n",
      "25%     713.250000        106.403867\n",
      "50%    1425.500000        143.890380\n",
      "75%    2137.750000        181.406681\n",
      "max    2850.000000        239.954998\n",
      "        product_id  forecast_dec2016\n",
      "count  2850.000000       2850.000000\n",
      "mean   1425.500000        193.491089\n",
      "std     822.868459          0.000000\n",
      "min       1.000000        193.491104\n",
      "25%     713.250000        193.491104\n",
      "50%    1425.500000        193.491104\n",
      "75%    2137.750000        193.491104\n",
      "max    2850.000000        193.491104\n",
      "  Model     Total Loss  Average Loss\n",
      "0    HW   91603.791712     32.141681\n",
      "1    LR  103594.567281     36.348971\n",
      "2    RF   80612.292063     28.285015\n",
      "3   XGB  181524.025344     63.692640\n",
      "   product_id  actual_dec2016  forecast_hw  forecast_lr  forecast_rf  \\\n",
      "0           1       88.464626    84.049333    97.006825    89.466394   \n",
      "1           2      114.534528   107.031894   119.960329   113.521466   \n",
      "2           3      220.935945   190.199567    86.378127   190.199567   \n",
      "3           4      263.674180   204.396496   204.396496   204.396496   \n",
      "4           5      195.598558   205.954112   219.227684   204.938414   \n",
      "5           6      112.047205   117.751906   117.751906   117.751906   \n",
      "6           7      179.729435   156.566980   172.142244   156.702491   \n",
      "7           8      174.173740   149.371984   170.512521   162.017805   \n",
      "8           9      150.134804   146.809925   146.809925   146.809925   \n",
      "9          10      198.450192   182.034476   192.488663   189.769923   \n",
      "\n",
      "   forecast_xgb     loss_hw     loss_lr     loss_rf    loss_xgb  \n",
      "0    193.491104    5.542169   15.654045    1.835795  192.466743  \n",
      "1    193.491104   35.425823    5.014289    4.783463   72.968234  \n",
      "2    193.491104   82.217915  359.933869   82.217915   73.413257  \n",
      "3    193.491104  141.571510  141.571510  141.571510  167.616602  \n",
      "4    193.491104    7.889458   18.002029    7.115641    3.519456  \n",
      "5    193.491104    3.134409    3.134409    3.134409   44.748796  \n",
      "6    193.491104   52.604742   17.231431   52.296981   19.623419  \n",
      "7    193.491104   80.439878   11.874481   39.425511   36.589707  \n",
      "8    193.491104   15.260168   15.260168   15.260168   84.593461  \n",
      "9    193.491104   10.157078    3.688643    5.370839    3.068391  \n"
     ]
    }
   ],
   "source": [
    "def compute_loss(row, pred_col):\n",
    "    actual = row['actual_dec2016']\n",
    "    pred = row[pred_col]\n",
    "    under = max(actual - pred, 0) * row['unit_opportunity_loss']\n",
    "    over = max(pred - actual, 0) * row['unit_inventory_cost']\n",
    "    return under + over\n",
    "\n",
    "df_eval['loss_hw'] = df_eval.apply(lambda row: compute_loss(row, 'forecast_hw'), axis=1)\n",
    "df_eval['loss_lr'] = df_eval.apply(lambda row: compute_loss(row, 'forecast_lr'), axis=1)\n",
    "df_eval['loss_rf'] = df_eval.apply(lambda row: compute_loss(row, 'forecast_rf'), axis=1)\n",
    "df_eval['loss_xgb'] = df_eval.apply(lambda row: compute_loss(row, 'forecast_xgb'), axis=1)\n",
    "\n",
    "print(df_forecast_hw.describe())  # HW summary\n",
    "print(df_forecast_lr.describe())  # LR\n",
    "print(df_forecast_rf.describe())  # RF\n",
    "print(df_forecast_xgb.describe()) #xgb\n",
    "loss_summary = pd.DataFrame({\n",
    "    'Model': ['HW', 'LR', 'RF', 'XGB'],\n",
    "    'Total Loss': [df_eval['loss_hw'].sum(), df_eval['loss_lr'].sum(), df_eval['loss_rf'].sum(), df_eval['loss_xgb'].sum()],\n",
    "    'Average Loss': [df_eval['loss_hw'].mean(), df_eval['loss_lr'].mean(), df_eval['loss_rf'].mean(), df_eval['loss_xgb'].mean()]\n",
    "})\n",
    "print(loss_summary)\n",
    "print(df_eval[['product_id', 'actual_dec2016', 'forecast_hw', 'forecast_lr', 'forecast_rf', 'forecast_xgb', 'loss_hw', 'loss_lr', 'loss_rf', 'loss_xgb']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059dc93a",
   "metadata": {},
   "source": [
    "#### PyTorch LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b3f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23d15bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Total Loss: 987650.2074498702\n",
      "        product_id  forecast_dec2016\n",
      "count  2850.000000       2850.000000\n",
      "mean   1425.500000         18.329829\n",
      "std     822.868459         26.236903\n",
      "min       1.000000          5.620905\n",
      "25%     713.250000         11.390396\n",
      "50%    1425.500000         13.529449\n",
      "75%    2137.750000         15.959415\n",
      "max    2850.000000        220.170671\n"
     ]
    }
   ],
   "source": [
    "# Assume df_sales, dates, n_products=2850, ts_df_full from prior code\n",
    "# (full 59-month series per product with NaNs; regenerate if needed as in earlier snippets)\n",
    "\n",
    "def create_features(ts):\n",
    "    \"\"\"Create multivariate features: trend, month_sin, month_cos, lag1, lag12\"\"\"\n",
    "    trend = np.arange(len(ts))\n",
    "    month = ts.index.month.values\n",
    "    month_sin = np.sin(2 * np.pi * (month - 1) / 12)\n",
    "    month_cos = np.cos(2 * np.pi * (month - 1) / 12)\n",
    "    lag1 = ts.shift(1, fill_value=ts.mean())\n",
    "    lag12 = ts.shift(12, fill_value=ts.mean())\n",
    "    features = pd.DataFrame({\n",
    "        'trend': trend, 'month_sin': month_sin, 'month_cos': month_cos,\n",
    "        'lag1': lag1, 'lag12': lag12\n",
    "    }, index=ts.index)\n",
    "    return features\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, features, target, seq_len=12):\n",
    "        self.features = features.values  # (n_timesteps, 5)\n",
    "        self.target = target.values  # (n_timesteps,)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx:idx + self.seq_len]  # Fixed length (seq_len, 5)\n",
    "        y = self.target[idx + self.seq_len]\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_size=5, hidden_size=50, num_layers=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        dropout_val = dropout if num_layers > 1 else 0\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_val)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        return self.fc(h_n[-1]).squeeze(1)  # (batch,)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Forecasts dict\n",
    "forecasts_lstm = {}\n",
    "for pid in range(1, n_products + 1):\n",
    "    ts = ts_df_full[pid]  # Series with NaNs\n",
    "    num_obs = len(ts.dropna())\n",
    "    if num_obs < 12:  # Fallback for too sparse\n",
    "        forecasts_lstm[pid] = ts.mean()\n",
    "        continue\n",
    "    \n",
    "    # Fill missing values for consecutive sequences\n",
    "    ts_filled = ts.interpolate(method='linear').fillna(ts.mean())\n",
    "    feat_df = create_features(ts_filled)\n",
    "    \n",
    "    # Dataset (fixed length, no NaNs)\n",
    "    dataset = TimeSeriesDataset(feat_df, ts_filled, seq_len=12)\n",
    "    loader = DataLoader(dataset, batch_size=8, shuffle=True)  # Small batch for efficiency\n",
    "    \n",
    "    # Model\n",
    "    model = LSTMPredictor(input_size=5).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Train\n",
    "    model.train()\n",
    "    for epoch in range(50):\n",
    "        epoch_loss = 0\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device).unsqueeze(1)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "    \n",
    "    # Predict Dec 2016 (extrapolate from last 12 months)\n",
    "    model.eval()\n",
    "    last_feat = feat_df.iloc[-12:].values  # (12, 5)\n",
    "    with torch.no_grad():\n",
    "        last_seq = torch.tensor(last_feat, dtype=torch.float32).unsqueeze(0).to(device)  # (1, 12, 5)\n",
    "        pred = model(last_seq).item()\n",
    "    forecasts_lstm[pid] = max(pred, 0)\n",
    "\n",
    "df_forecast_lstm = pd.DataFrame(list(forecasts_lstm.items()), columns=['product_id', 'forecast_dec2016'])\n",
    "\n",
    "# Evaluation (reuse compute_loss from prior; merge with df_actual, df_costs)\n",
    "df_eval_lstm = df_actual.merge(df_forecast_lstm, on='product_id').merge(df_costs, on='product_id')\n",
    "df_eval_lstm['loss_lstm'] = df_eval_lstm.apply(lambda row: compute_loss(row, 'forecast_dec2016'), axis=1)\n",
    "print(\"LSTM Total Loss:\", df_eval_lstm['loss_lstm'].sum())\n",
    "print(df_forecast_lstm.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322db844",
   "metadata": {},
   "source": [
    "#### Prophet Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6dc635cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 312 historical observations across 10 products.\n",
      "   product_id  unit_opportunity_loss  unit_inventory_cost\n",
      "0           1               3.802998             8.771663\n",
      "1           2               3.046561             9.306642\n",
      "2           3               6.471050             5.191301\n",
      "3           4               4.413751             5.327533\n",
      "4           5               7.698247             9.266093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:03:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:03:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:03:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:03:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:03:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:03:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:03:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:03:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:03:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:03:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:03:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:03:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:03:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:03:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:03:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:03:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:03:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:03:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:03:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:03:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forecasts for December 2016:\n",
      "   product_id  forecast  alpha  yhat_mean  sigma\n",
      "0           1      0.00   0.30   -1352.70  11.24\n",
      "1           2    158.54   0.25     165.30   9.86\n",
      "2           3     87.74   0.55      85.93  13.12\n",
      "3           4    121.78   0.45     124.48  22.92\n",
      "4           5    118.09   0.45     120.41  19.96\n",
      "5           6    111.23   0.31     122.54  23.08\n",
      "6           7      0.00   0.86    -143.87  19.67\n",
      "7           8     41.69   0.41      46.12  19.74\n",
      "8           9     55.45   0.39      63.75  28.51\n",
      "9          10     82.92   0.43      87.14  24.96\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress Prophet warnings for clean output\n",
    "\n",
    "# Step 1: Generate fake historical sales data (sparse)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "n_products = 10  # Use 10 for demo; set to 2850 for full\n",
    "dates = pd.date_range(start='2012-01-01', end='2016-11-01', freq='MS')  # 59 months\n",
    "sales_data = []\n",
    "\n",
    "for prod_id in range(1, n_products + 1):\n",
    "    # Simulate sparsity: random 20-50 observations per product\n",
    "    n_obs = np.random.randint(20, 50)\n",
    "    selected_dates = np.random.choice(dates, size=n_obs, replace=False)\n",
    "    # Fake order amounts: base 100 + seasonal sin wave + noise (lognormal for positivity)\n",
    "    months = np.arange(len(dates))\n",
    "    seasonal = 20 * np.sin(2 * np.pi * months / 12)  # Annual seasonality\n",
    "    base = 100 + seasonal[:n_obs]  # Align to selected dates\n",
    "    order_amounts = np.random.lognormal(mean=np.log(base), sigma=0.3)\n",
    "    for date, amount in zip(selected_dates, order_amounts):\n",
    "        sales_data.append({'product_id': prod_id, 'ds': date, 'y': amount})\n",
    "\n",
    "df_sales = pd.DataFrame(sales_data)\n",
    "print(f\"Generated {len(df_sales)} historical observations across {n_products} products.\")\n",
    "\n",
    "# Step 2: Generate fake costs data\n",
    "costs_data = {\n",
    "    'product_id': range(1, n_products + 1),\n",
    "    'unit_opportunity_loss': np.random.uniform(1, 10, n_products),  # cu\n",
    "    'unit_inventory_cost': np.random.uniform(1, 10, n_products)     # co\n",
    "}\n",
    "df_costs = pd.DataFrame(costs_data)\n",
    "print(df_costs.head())\n",
    "\n",
    "# Step 3: Forecast for December 2016\n",
    "forecasts = []\n",
    "dec_2016 = pd.to_datetime('2016-12-01')\n",
    "\n",
    "for prod_id in df_sales['product_id'].unique():\n",
    "    # Historical data for this product\n",
    "    hist = df_sales[df_sales['product_id'] == prod_id][['ds', 'y']].sort_values('ds')\n",
    "    \n",
    "    if len(hist) == 0:\n",
    "        # Handle no data: use global mean (or skip/error in production)\n",
    "        global_mean = df_sales['y'].mean()\n",
    "        forecasts.append({'product_id': prod_id, 'forecast': global_mean})\n",
    "        continue\n",
    "    \n",
    "    # Fit Prophet\n",
    "    m = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)\n",
    "    m.fit(hist)\n",
    "    \n",
    "    # Make future dataframe for Dec 2016\n",
    "    future = m.make_future_dataframe(periods=1, freq='MS', include_history=False)\n",
    "    fc = m.predict(future)\n",
    "    \n",
    "    # Extract forecast components\n",
    "    yhat = fc['yhat'].iloc[-1]\n",
    "    yhat_lower = fc['yhat_lower'].iloc[-1]\n",
    "    yhat_upper = fc['yhat_upper'].iloc[-1]\n",
    "    \n",
    "    # Approximate sigma from 80% PI (z=1.282 for 80%)\n",
    "    sigma = (yhat_upper - yhat_lower) / (2 * 1.282)\n",
    "    sigma = max(sigma, 0.01)  # Avoid zero/negative sigma\n",
    "    \n",
    "    # Get costs for alpha\n",
    "    prod_costs = df_costs[df_costs['product_id'] == prod_id].iloc[0]\n",
    "    cu = prod_costs['unit_opportunity_loss']\n",
    "    co = prod_costs['unit_inventory_cost']\n",
    "    alpha = cu / (cu + co)\n",
    "    \n",
    "    # Î±-quantile forecast\n",
    "    z_alpha = norm.ppf(alpha)\n",
    "    quantile_forecast = yhat + z_alpha * sigma\n",
    "    quantile_forecast = max(quantile_forecast, 0)  # Ensure non-negative\n",
    "    \n",
    "    forecasts.append({\n",
    "        'product_id': prod_id,\n",
    "        'forecast': quantile_forecast,\n",
    "        'alpha': alpha,\n",
    "        'yhat_mean': yhat,\n",
    "        'sigma': sigma\n",
    "    })\n",
    "\n",
    "# Step 4: Output results\n",
    "df_forecasts = pd.DataFrame(forecasts)\n",
    "print(\"\\nForecasts for December 2016:\")\n",
    "print(df_forecasts.round(2))\n",
    "\n",
    "# For full scale (2850 products), the loop scales well; add parallelization if needed\n",
    "# e.g., from joblib import Parallel, delayed; Parallel(n_jobs=-1)(delayed(forecast_func)(prod) for prod in products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f042b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b3038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b51d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basepy31306",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
