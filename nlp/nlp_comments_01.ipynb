{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c70e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "from rapidfuzz import fuzz  # Optional for fuzzy matching; install if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c80b8dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\jalal\\AppData\\Local\\Temp\\ipykernel_38292\\125663428.py:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df = pd.read_csv('data\\data.csv')  # Replace with your file path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed sample: great quality material complaint worth every penny test\n"
     ]
    }
   ],
   "source": [
    "# Load DataFrame\n",
    "df = pd.read_csv('data\\data.csv')  # Replace with your file path\n",
    "comments_col = 'comments'  # Your column name\n",
    "\n",
    "# Initialize tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    # Lowercase and remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower())\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words and lemmatize\n",
    "    lemmatized = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words and len(token) > 2]\n",
    "    return ' '.join(lemmatized)\n",
    "\n",
    "# Apply preprocessing\n",
    "df['processed_comments'] = df[comments_col].apply(preprocess_text)\n",
    "print(f\"Preprocessed sample: {df['processed_comments'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc42393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 frequent bigrams: [(('test', 'plus'), 16), (('plus', 'color'), 16), (('color', 'option'), 16), (('option', 'fantastic'), 16), (('billing', 'error'), 11)]\n",
      "Sample key terms/phrases: ['test']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to extract bigrams from processed text\n",
    "def extract_bigrams(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return list(ngrams(tokens, 2))  # Bigrams\n",
    "\n",
    "# Extract all bigrams\n",
    "df['bigrams'] = df['processed_comments'].apply(extract_bigrams)\n",
    "\n",
    "# Flatten and count bigram frequencies (optional, for basic stats)\n",
    "all_bigrams = [bigram for bigrams_list in df['bigrams'] for bigram in bigrams_list]\n",
    "bigram_freq = Counter(all_bigrams)\n",
    "print(\"Top 5 frequent bigrams:\", bigram_freq.most_common(5))\n",
    "\n",
    "# TF-IDF for unigrams and bigrams\n",
    "# For unigrams\n",
    "vectorizer_uni = TfidfVectorizer(max_features=1000, stop_words='english', ngram_range=(1,1))\n",
    "tfidf_uni = vectorizer_uni.fit_transform(df['processed_comments'])\n",
    "feature_names_uni = vectorizer_uni.get_feature_names_out()\n",
    "\n",
    "# For bigrams\n",
    "vectorizer_bi = TfidfVectorizer(max_features=500, stop_words='english', ngram_range=(2,2))\n",
    "tfidf_bi = vectorizer_bi.fit_transform(df['processed_comments'])\n",
    "feature_names_bi = vectorizer_bi.get_feature_names_out()\n",
    "\n",
    "# Get top key terms/phrases (combine uni + bi, score > threshold)\n",
    "def get_top_terms(tfidf_matrix, feature_names, top_n=50, threshold=0.1):\n",
    "    scores = tfidf_matrix.mean(axis=0).A1\n",
    "    top_indices = scores.argsort()[-top_n:][::-1]\n",
    "    top_terms = [(feature_names[i], scores[i]) for i in top_indices if scores[i] > threshold]\n",
    "    return top_terms\n",
    "\n",
    "top_unigrams = get_top_terms(tfidf_uni, feature_names_uni)\n",
    "top_bigrams = get_top_terms(tfidf_bi, feature_names_bi)\n",
    "\n",
    "# Combine into a single list of key terms/phrases\n",
    "key_terms = [term[0] for term in top_unigrams + top_bigrams]\n",
    "print(\"Sample key terms/phrases:\", key_terms[:10])\n",
    "\n",
    "# Optional: Save to DataFrame for UI\n",
    "df['key_phrases'] = df['processed_comments'].apply(lambda x: [phrase for phrase in key_terms if phrase in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ef95b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows matching 'test': 90\n"
     ]
    }
   ],
   "source": [
    "def filter_by_term(df, term, column=comments_col, fuzzy_threshold=80):\n",
    "    filtered = df[df[column].str.contains(term, case=False, na=False)]\n",
    "    # Optional fuzzy: For more flexible matching\n",
    "    # fuzzy_matches = df[df[column].apply(lambda x: fuzz.partial_ratio(str(x), term) >= fuzzy_threshold if pd.notna(x) else False)]\n",
    "    return filtered\n",
    "\n",
    "# Test\n",
    "sample_term = key_terms[0]\n",
    "filtered_df = filter_by_term(df, sample_term)\n",
    "print(f\"Rows matching '{sample_term}': {len(filtered_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e524f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>comments</th>\n",
       "      <th>processed_comments</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>key_phrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td>5</td>\n",
       "      <td>Great quality materials. No complaints here, w...</td>\n",
       "      <td>great quality material complaint worth every p...</td>\n",
       "      <td>[(great, quality), (quality, material), (mater...</td>\n",
       "      <td>[test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-09-14</td>\n",
       "      <td>5</td>\n",
       "      <td>Amazing build quality! It feels premium and wo...</td>\n",
       "      <td>amazing build quality feel premium work flawle...</td>\n",
       "      <td>[(amazing, build), (build, quality), (quality,...</td>\n",
       "      <td>[test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-07-20</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-08-09</td>\n",
       "      <td>5</td>\n",
       "      <td>Outstanding value. Five stars all the way. (Te...</td>\n",
       "      <td>outstanding value five star way test plus colo...</td>\n",
       "      <td>[(outstanding, value), (value, five), (five, s...</td>\n",
       "      <td>[test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2024-10-19</td>\n",
       "      <td>2</td>\n",
       "      <td>Took forever to get a response from support. F...</td>\n",
       "      <td>took forever get response support frustrating ...</td>\n",
       "      <td>[(took, forever), (forever, get), (get, respon...</td>\n",
       "      <td>[test]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  rating                                           comments  \\\n",
       "0   1  2024-06-05       5  Great quality materials. No complaints here, w...   \n",
       "1   2  2024-09-14       5  Amazing build quality! It feels premium and wo...   \n",
       "2   3  2024-07-20       3                                                NaN   \n",
       "3   4  2024-08-09       5  Outstanding value. Five stars all the way. (Te...   \n",
       "4   5  2024-10-19       2  Took forever to get a response from support. F...   \n",
       "\n",
       "                                  processed_comments  \\\n",
       "0  great quality material complaint worth every p...   \n",
       "1  amazing build quality feel premium work flawle...   \n",
       "2                                                      \n",
       "3  outstanding value five star way test plus colo...   \n",
       "4  took forever get response support frustrating ...   \n",
       "\n",
       "                                             bigrams key_phrases  \n",
       "0  [(great, quality), (quality, material), (mater...      [test]  \n",
       "1  [(amazing, build), (build, quality), (quality,...      [test]  \n",
       "2                                                 []          []  \n",
       "3  [(outstanding, value), (value, five), (five, s...      [test]  \n",
       "4  [(took, forever), (forever, get), (get, respon...      [test]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basepy31306",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
